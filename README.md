# ğŸ“š Vibe Logs Repository

This repository contains my **vibe logs** for class papers.  
Each paper is linked along with my ChatGPT vibe log discussion that captures my thoughts, breakdowns, and explorations.

---

## Table of Contents
- [DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines](#dspy-compiling-declarative-language-model-calls-into-self-improving-pipelines)
- [TVM: An Automated End-to-End Optimizing Compiler for Deep Learning](#tvm-an-automated-end-to-end-optimizing-compiler-for-deep-learning)
 - [Relay: A High-Level Compiler for Deep Learning](#relay-a-high-level-compiler-for-deep-learning)
 - [MTP: A Meaning-Typed Language Abstraction for AI-Integrated Programming](#mtp-a-meaning-typed-language-abstraction-for-ai-integrated-programming)
- [GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning](#gepa-reflective-prompt-evolution-can-outperform-reinforcement-learning)
- [Ansor: Generating High-Performance Tensor Programs for Deep Learning](#ansor-generating-high-performance-tensor-programs-for-deep-learning)
- [PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation](#pytorch-2-faster-machine-learning-through-dynamic-python-bytecode-transformation-and-graph-compilation)
- [TorchBench: Benchmarking PyTorch with High API Surface Coverage](#torchbench-benchmarking-pytorch-with-high-api-surface-coverage)
- [TorchTitan: One-stop PyTorch native solution for production ready LLM pre-training](#torchtitan-one-stop-pytorch-native-solution-for-production-ready-llm-pre-training)
- [ECLIP: Energy-efficient and Practical Co-Location of ML Inference on Spatially Partitioned GPUs](#eclip-energy-efficient-and-practical-co-location-of-ml-inference-on-spatially-partitioned-gpus)

---

## DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines
- ğŸ“„ [Paper Link](https://arxiv.org/abs/2310.03714)  
- ğŸ“ [Vibe Log](./vibe_logs/DSPy_vibe_log.md)  

---

## TVM: An Automated End-to-End Optimizing Compiler for Deep Learning
- ğŸ“„ [Paper Link](https://arxiv.org/abs/1802.04799)  
- ğŸ“ [Vibe Log](./vibe_logs/TVM_vibe_log.md)  

---

## Relay: A High-Level Compiler for Deep Learning
- ğŸ“„ [Paper Link](https://arxiv.org/abs/1904.08368)  
- ğŸ“ [Vibe Log](./vibe_logs/Relay_vibe_log.md)  

---

## MTP: A Meaning-Typed Language Abstraction for AI-Integrated Programming
- ğŸ“„ [Paper Link](https://arxiv.org/abs/2405.08965)  
- ğŸ“ [Vibe Log](./vibe_logs/MTP_vibe_log.md)  

---

## GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning
- ğŸ“„ [Paper Link](https://arxiv.org/abs/2507.19457)  
- ğŸ“ [Vibe Log](./vibe_logs/GEPA_vibe_log.md)  

---

## Ansor: Generating High-Performance Tensor Programs for Deep Learning
- ğŸ“„ [Paper Link](https://arxiv.org/abs/2006.06762)  
- ğŸ“ [Vibe Log](./vibe_logs/Ansor_vibe_log.md)  

---

## PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation
- ğŸ“„ [Paper Link](https://dl.acm.org/doi/10.1145/3620665.3640366)  
- ğŸ“ [Vibe Log](./vibe_logs/PyTorch_vibe_log.md)  

---

## TorchBench: Benchmarking PyTorch with High API Surface Coverage
- ğŸ“„ [Paper Link](https://arxiv.org/abs/2304.14226)  
- ğŸ“ [Vibe Log](./vibe_logs/TorchBench_vibe_log.md)  

---

## TorchTitan: One-stop PyTorch native solution for production ready LLM pre-training
- ğŸ“„ [Paper Link](https://arxiv.org/abs/2410.06511)  
- ğŸ“ [Vibe Log](./vibe_logs/TorchTitan_vibe_log.md)  

---

## ECLIP: Energy-efficient and Practical Co-Location of ML Inference on Spatially Partitioned GPUs
- ğŸ“„ [Paper Link](https://arxiv.org/abs/2506.12598)  
- ğŸ“ [Vibe Log](./vibe_logs/ECLIP_vibe_log.md)  

---

